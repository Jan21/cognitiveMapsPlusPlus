# Quick Start: Model Variants

## ‚úÖ All 5 Variants Tested and Working!

```
‚úÖ V1 Residual          |    113,644 params | Stable training
‚úÖ V2 Transformer       |    176,236 params | Long-range dependencies
‚úÖ V3 UNet              |     60,364 params | Skip connections
‚úÖ V4 Simple            |     71,852 params | ‚≠ê Recommended first try
‚úÖ V5 GRU               |     95,407 params | Sequential modeling
```

---

## Try Variant V4 First (Most Reliable)

### Step 1: Update your model config

Edit your training config or model config to include:

```yaml
model:
  variant: v4_simple
  d_model: 256
  num_iterations: 2
  upscale_depth: 5
  dropout: 0.15
```

### Step 2: Run training

```bash
python train.py  # or however you run training
```

### Step 3: Monitor metrics

Watch for:
- `train_loss` - should decrease steadily
- `val_loss` - should decrease
- `val_accuracy` - should increase
- `val_exact_match` - should increase
- `val_validity` - should approach 1.0

---

## If V4 Doesn't Work

### Option 1: Try V1 (More capacity)

```yaml
model:
  variant: v1_residual
  d_model: 128
  num_iterations: 3
  upscale_depth: 5
  dropout: 0.1
```

### Option 2: Try different learning rate

```yaml
learning_rate: 1e-3  # Instead of 3e-3
```

### Option 3: Check your data

The most common cause of "model not learning" is data issues:

```python
# Add this to your training script
for batch in train_dataloader:
    print(f"Input shape: {batch['input'].shape}")
    print(f"Input sample: {batch['input'][0]}")
    for i in range(5):
        if i in batch:
            print(f"Level {i} labels: {batch[i].shape}, {batch[i][0]}")
    break  # Just check first batch
```

Verify:
- ‚úì Input tokens are in range [0, vocab_size-1]
- ‚úì Labels have -100 for start/end positions
- ‚úì Labels are in range [0, vocab_size-1] (except -100)
- ‚úì Batch shapes match expected dimensions

---

## All Variant Options

### V1: Residual Upsample (Stable & Powerful)
```yaml
model:
  variant: v1_residual
  d_model: 128
  num_iterations: 3
  upscale_depth: 5
  dropout: 0.1
```
**Pros:** Most powerful, stable gradients, proper residual connections
**Cons:** More parameters (113k with d_model=64)

---

### V2: Transformer (Attention-Based)
```yaml
model:
  variant: v2_transformer
  d_model: 128
  num_iterations: 2
  upscale_depth: 5
  nhead: 4
  dropout: 0.1
```
**Pros:** Self-attention, great for long-range dependencies
**Cons:** More memory, may need lower LR (1e-3)

---

### V3: U-Net (Skip Connections)
```yaml
model:
  variant: v3_unet
  d_model: 128
  num_iterations: 3
  upscale_depth: 5
  dropout: 0.1
```
**Pros:** Skip connections preserve details, fewest parameters (60k)
**Cons:** Can overfit, may need more regularization

---

### V4: Simple Progressive (‚≠ê Recommended)
```yaml
model:
  variant: v4_simple
  d_model: 256  # Larger to compensate for sharing
  num_iterations: 2
  upscale_depth: 5
  dropout: 0.15
```
**Pros:** Most reliable, parameter sharing, easiest to train
**Cons:** Less expressive due to parameter sharing

---

### V5: GRU with Attention
```yaml
model:
  variant: v5_gru
  d_model: 128
  num_iterations: 2
  upscale_depth: 5
  dropout: 0.1
```
**Pros:** Good sequential modeling, bidirectional context
**Cons:** Slower than conv-based, use LR ~2e-3

---

## Debugging Tips

### Loss not decreasing?

1. **Check data** (most common issue)
2. **Lower learning rate**: Try 1e-3 or 3e-4
3. **Smaller model**: Try d_model=64
4. **Overfit one batch**: Disable validation, train on just 1 batch

### Loss exploding (NaN)?

1. **Lower learning rate**: Try 1e-4
2. **Gradient clipping**: Should already be enabled (1.0)
3. **Check for bad data**: Look for extreme values

### Model overfitting?

1. **Increase dropout**: Try 0.2 or 0.3
2. **Use V4** (parameter sharing helps)
3. **Add weight decay**: Try 1e-4
4. **Get more data** if possible

---

## Example Training Command

```bash
# If using Hydra config system
python train.py model.variant=v4_simple model.d_model=256

# Or edit config file directly
python train.py
```

---

## Files Created

| File | Description |
|------|-------------|
| `model/architecture/rnn_middle_predictor_variants.py` | All 5 new variants |
| `model/architecture/variant_factory.py` | Factory to create models |
| `config/model_variants.yaml` | Example configs |
| `docs/model_variants_analysis.md` | Detailed analysis |
| `MODEL_VARIANTS_README.md` | Overview |
| `QUICK_START.md` | This file |

---

## Need Help?

1. Check `docs/model_variants_analysis.md` for detailed info
2. Look at `config/model_variants.yaml` for more examples
3. Verify data pipeline is correct
4. Try overfitting a single batch first
5. Make sure you can reproduce the test: `python test_variants.py`

Good luck! üöÄ
