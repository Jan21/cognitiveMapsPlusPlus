# @package _global_

# Optuna-based learning rate search configuration
# Requires: pip install hydra-optuna-sweeper
# Usage: python train.py +sweeps=lr_optuna --multirun

defaults:
  - override /hydra/sweeper: optuna

hydra:
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}_optuna_lr
    subdir: ${hydra.job.num}_lr_${training.learning_rate}
  sweeper:
    storage: "sqlite:///temp/optuna_lr_study_v2.db"  # Use in-memory storage (no persistence)
    study_name: lr_search_study
    direction: minimize
    n_trials: 20
    n_jobs: 1
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 42
      n_startup_trials: 5
    params:
      training.learning_rate: tag(log, interval(1e-5, 1e-2))

training:
  max_epochs: 50
